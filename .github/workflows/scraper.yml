name: Scrape data and publish Pages

on:
  schedule:
    - cron: "0 16 * * *"   # every 6 hours
  workflow_dispatch:

permissions:
  contents: write

jobs:
  pipeline: 
    runs-on: ubuntu-latest

    steps:
      - name: Checkout main
        uses: actions/checkout@v4
        with:
          fetch-depth: 0

      - name: Set up Python
        uses: actions/setup-python@v5
        with:
          python-version: "3.11"

      - name: Install dependencies
        run: |
          pip install -r requirements.txt || true

      - name: Run pipeline (scrape + build)
        run: |
          chmod +x run_pipeline.sh
          ./run_pipeline.sh

      # -------------------------
      # Commit DATA to main
      # -------------------------
      - name: Commit CSV data (if changed)
        run: |
          git config user.name "github-actions[bot]"
          git config user.email "41898282+github-actions[bot]@users.noreply.github.com"

          shopt -s globstar
          git add results/**/*.csv results/processed/*.csv || true

          if ! git diff --cached --quiet; then
            git commit -m "chore(data): update results ($(date -u +'%Y-%m-%d %H:%M:%S UTC'))"
            git push origin main
            echo "‚úÖ Data committed to main"
          else
            echo "‚ÑπÔ∏è No data changes"
          fi

      # -------------------------
      # Publish Pages
      # -------------------------
      - name: Publish GitHub Pages
        run: |
          git checkout --orphan gh-pages
          git rm -rf .

          cp -r docs/* .
          touch .nojekyll

          git add .
          git commit -m "pages: deploy site ($(date -u +'%Y-%m-%d %H:%M:%S UTC'))"
          git push -f origin gh-pages

          echo "üöÄ Pages updated"
