name: JAV.guru Scraper & Publish Results

on:
  schedule:
    - cron: "30 6 * * *"  # Every day at 12:00 PM IST
  workflow_dispatch:      # Optional: also allow manual runs
  
permissions:
  contents: write  # Allow committing changes

jobs:
  scrape-and-publish:
    runs-on: ubuntu-latest

    steps:
      - name: Checkout repository
        uses: actions/checkout@v4
        with:
          fetch-depth: 0

      - name: Set up Python
        uses: actions/setup-python@v4
        with:
          python-version: "3.x"

      - name: Install dependencies
        run: |
          python -m pip install --upgrade pip
          pip install cloudscraper beautifulsoup4

      - name: Run scraper
        run: |
          python scraper.py

      - name: Build index.html
        run: |
          python build_index.py

      - name: Show results folder
        run: |
          echo "Files in results/:"
          ls -la results || true

      - name: Commit results back to repo (if changed)
        run: |
          git config user.name "github-actions[bot]"
          git config user.email "41898282+github-actions[bot]@users.noreply.github.com"

          git add results/*.csv results/index.html || true

          if [ -n "$(git status --porcelain)" ]; then
            git commit -m "chore(scraper): update results and index ($(date -u +'%Y-%m-%d %H:%M:%S UTC'))" || true
            git push
            echo "✅ Committed and pushed results + index."
          else
            echo "ℹ️ No changes to commit."
          fi

      - name: Deploy results to GitHub Pages
        uses: peaceiris/actions-gh-pages@v4
        with:
          github_token: ${{ secrets.GITHUB_TOKEN }}
          publish_dir: ./results
          user_name: "github-actions[bot]"
          user_email: "41898282+github-actions[bot]@users.noreply.github.com"
          keep_files: true
