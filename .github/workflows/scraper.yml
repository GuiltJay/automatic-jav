name: JAV.guru Scraper & Publish Results

on:
  schedule:
    - cron: "30 11 * * *"  # Every day at 5:00 PM IST
  workflow_dispatch:        # Optional: also allow manual runs

  
permissions:
  contents: write  # Allow committing changes

jobs:
  scrape-and-publish:
    runs-on: ubuntu-latest

    steps:
      - name: Checkout repository
        uses: actions/checkout@v4
        with:
          fetch-depth: 0

      - name: Set up Python
        uses: actions/setup-python@v4
        with:
          python-version: "3.x"

      - name: Install dependencies
        run: |
          python -m pip install --upgrade pip
          pip install cloudscraper beautifulsoup4

      - name: Run Full Pipeline
        run: |
          bash run_pipeline.sh

      - name: Show results folder
        run: |
          echo "Files in results/:"
          ls -la results || true

      - name: Commit CSV data (if changed)
        run: |
          git config user.name "github-actions[bot]"
          git config user.email "41898282+github-actions[bot]@users.noreply.github.com"

          shopt -s globstar
          git add docs/*.html results/**/*.csv results/processed/*.csv || true

          if ! git diff --cached --quiet; then
            git commit -m "chore(data): update results ($(date -u +'%Y-%m-%d %H:%M:%S UTC'))"
            git push origin main
            echo "✅ Data committed to main"
          else
            echo "ℹ️ No data changes"
          fi

      # -------------------------
      # Publish Pages
      # -------------------------
      - name: Deploy results to GitHub Pages
        uses: peaceiris/actions-gh-pages@v4
        with:
          github_token: ${{ secrets.GITHUB_TOKEN }}
          publish_dir: ./docs
          user_name: "github-actions[bot]"
          user_email: "41898282+github-actions[bot]@users.noreply.github.com"
          keep_files: false
